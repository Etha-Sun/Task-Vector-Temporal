{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_schapiro/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an MNIST benchmark to run:\n",
      "1. SplitMNIST\n",
      "2. PermutedMNIST\n",
      "3. RotatedMNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_schapiro/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the Naive.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training Joint Baseline Model on All Tasks ###\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:23<00:00,  2.31it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8211\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "  4%|▍         | 18/469 [00:07<03:06,  2.42it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 159\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid choice. Defaulting to SplitMNIST.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m     dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mcontinual_learning_task_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_experiences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m, in \u001b[0;36mcontinual_learning_task_vectors\u001b[0;34m(dataset_name, n_experiences)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dataset name.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 2. Train the joint baseline model\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m joint_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_joint_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 3. Model, Optimizer, and Criterion\u001b[39;00m\n\u001b[1;32m     66\u001b[0m model_pre \u001b[38;5;241m=\u001b[39m SimpleMLP(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mtrain_joint_baseline\u001b[0;34m(benchmark, device, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Combine all tasks into a single dataset\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experience \u001b[38;5;129;01min\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mtrain_stream:\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint Baseline Model Training Completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m joint_model\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/base_sgd.py:213\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     experiences: Union[TDatasetExperience, Iterable[TDatasetExperience]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    212\u001b[0m ):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mget_last_metrics()\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/base.py:163\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperience \u001b[38;5;129;01min\u001b[39;00m experiences_list:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/base_sgd.py:339\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_epoch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/update_type/sgd_update.py:38\u001b[0m, in \u001b[0;36mSGDUpdate.training_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_backward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_backward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Optimization step\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/base_sgd.py:261\u001b[0m, in \u001b[0;36mBaseSGDTemplate.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the backward pass.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from avalanche.benchmarks import SplitMNIST, PermutedMNIST, RotatedMNIST\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.supervised import Naive\n",
    "from numpy.linalg import lstsq\n",
    "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics\n",
    "from avalanche.logging import InteractiveLogger,  TextLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Helper function to compute task vector\n",
    "def compute_task_vector(model_pre, model_tuned):\n",
    "    task_vector = []\n",
    "    for p_pre, p_tuned in zip(model_pre.parameters(), model_tuned.parameters()):\n",
    "        task_vector.append((p_tuned.data - p_pre.data).detach().cpu().numpy())\n",
    "    return np.concatenate([p.flatten() for p in task_vector])\n",
    "\n",
    "# Helper function to check if a vector is in the span of other vectors\n",
    "def is_in_span(vector, span_vectors):\n",
    "    if not span_vectors:\n",
    "        return False, None\n",
    "    span_matrix = np.stack(span_vectors, axis=1)\n",
    "    coeffs, residuals, _, _ = lstsq(span_matrix, vector, rcond=None)\n",
    "    in_span = np.allclose(span_matrix @ coeffs, vector, atol=1e-5)\n",
    "    return in_span, coeffs\n",
    "\n",
    "# Function to train the joint baseline model on all tasks at once\n",
    "def train_joint_baseline(benchmark, device, epochs=1):\n",
    "    print(\"\\n### Training Joint Baseline Model on All Tasks ###\")\n",
    "    joint_model = SimpleMLP(num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(joint_model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(loss_metrics(epoch=True), loggers=[logger])\n",
    "\n",
    "    trainer = Naive(joint_model, optimizer, criterion,\n",
    "                    train_mb_size=128, device=device, evaluator=eval_plugin)\n",
    "    \n",
    "    # Combine all tasks into a single dataset\n",
    "    for experience in benchmark.train_stream:\n",
    "        trainer.train(experience, epochs=epochs)\n",
    "    \n",
    "    print(\"Joint Baseline Model Training Completed.\")\n",
    "    return joint_model\n",
    "\n",
    "# Main function implementing the algorithm with regret computation\n",
    "def continual_learning_task_vectors(dataset_name=\"SplitMNIST\", n_experiences=5):\n",
    "    # 1. Benchmark\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if dataset_name.lower() == \"splitmnist\":\n",
    "        benchmark = SplitMNIST(n_experiences=n_experiences, return_task_id=True)\n",
    "    elif dataset_name.lower() == \"permutedmnist\":\n",
    "        benchmark = PermutedMNIST(n_experiences=n_experiences)\n",
    "    elif dataset_name.lower() == \"rotatedmnist\":\n",
    "        benchmark = RotatedMNIST(n_experiences=n_experiences)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name.\")\n",
    "\n",
    "    # 2. Train the joint baseline model\n",
    "    joint_model = train_joint_baseline(benchmark, device, epochs=10)\n",
    "\n",
    "    # 3. Model, Optimizer, and Criterion\n",
    "    model_pre = SimpleMLP(num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model_pre.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 4. Active Task Vector Set and Regret Tracking\n",
    "    # Load pre-populated task vectors\n",
    "    with open(\"rotated_task_vectors.pkl\", \"rb\") as f:\n",
    "        task_vectors_active = pickle.load(f)\n",
    "    avg_regret = 0  # Tracks cumulative regret\n",
    "\n",
    "    # 5. Loop Through Tasks\n",
    "    for task_id, experience in enumerate(benchmark.train_stream):\n",
    "        print(f\"\\n### Training Task {task_id+1} ###\")\n",
    "\n",
    "        # Fine-tune continual learning model\n",
    "        model_tuned = SimpleMLP(num_classes=10).to(device)\n",
    "        model_tuned.load_state_dict(model_pre.state_dict())  # Copy weights\n",
    "        trainer = Naive(model_tuned, optimizer, criterion, train_mb_size=128, device=device)\n",
    "        trainer.train(experience, epochs=10)\n",
    "\n",
    "        # Compute task vector\n",
    "        task_vector = compute_task_vector(model_pre, model_tuned)\n",
    "        in_span, coefficients = is_in_span(task_vector, task_vectors_active)\n",
    "\n",
    "        if in_span:\n",
    "            print(f\"Task vector {task_id+1} is in span of previous task vectors.\")\n",
    "        else:\n",
    "            print(f\"Task vector {task_id+1} is NOT in span. Adding to active set.\")\n",
    "            task_vectors_active.append(task_vector)\n",
    "\n",
    "        # Evaluate losses for regret computation\n",
    "        test_stream = benchmark.test_stream[task_id]\n",
    "\n",
    "        # Evaluate losses for regret computation\n",
    "        cl_loss = evaluate_loss(model_tuned, test_stream, criterion, device, task_id)\n",
    "        joint_loss = evaluate_loss(joint_model, test_stream, criterion, device, task_id)\n",
    "\n",
    "        # Compute and track regret\n",
    "        regret = cl_loss - joint_loss\n",
    "        avg_regret += regret/n_experiences\n",
    "        print(f\"Regret on Task {task_id+1}: {regret:.4f}\")\n",
    "        print(f\"Average Regret: {avg_regret:.4f}\")\n",
    "\n",
    "        # Update pretrained model\n",
    "        model_pre.load_state_dict(model_tuned.state_dict())\n",
    "\n",
    "    print(\"\\nContinual Learning and Regret Evaluation Completed.\")\n",
    "\n",
    "def evaluate_loss(model, test_stream, criterion, device, task_id):\n",
    "    \"\"\"\n",
    "    Evaluate the loss of a model on a given test stream and dynamically retrieve the loss.\n",
    "    \"\"\"\n",
    "    # Setup the evaluation plugin to track loss\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        loss_metrics(stream=True),  # Log loss across the entire test stream\n",
    "        loggers=[TextLogger(open(\"/dev/null\", \"w\"))]  # Suppress logger output\n",
    "    )\n",
    "\n",
    "    # Create a Naive trainer only for evaluation\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    evaluator = Naive(model, optimizer, criterion, device=device, evaluator=eval_plugin)\n",
    "\n",
    "    # Run evaluation\n",
    "    evaluator.eval(test_stream)\n",
    "\n",
    "    # Dynamically retrieve the loss based on the task number\n",
    "    task_key = f\"Loss_Stream/eval_phase/test_stream/Task{task_id:03d}\"\n",
    "    eval_results = eval_plugin.get_last_metrics()\n",
    "    \n",
    "    if task_key in eval_results:\n",
    "        average_loss = eval_results[task_key]\n",
    "    else:\n",
    "        raise ValueError(f\"Loss key {task_key} not found in evaluation results.\")\n",
    "\n",
    "    return average_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Choose an MNIST benchmark to run:\")\n",
    "    print(\"1. SplitMNIST\")\n",
    "    print(\"2. PermutedMNIST\")\n",
    "    print(\"3. RotatedMNIST\")\n",
    "    \n",
    "    choice = input(\"Enter the number of your choice: \").strip()\n",
    "    if choice == \"1\":\n",
    "        dataset_name = \"SplitMNIST\"\n",
    "    elif choice == \"2\":\n",
    "        dataset_name = \"PermutedMNIST\"\n",
    "    elif choice == \"3\":\n",
    "        dataset_name = \"RotatedMNIST\"\n",
    "    else:\n",
    "        print(\"Invalid choice. Defaulting to SplitMNIST.\")\n",
    "        dataset_name = \"SplitMNIST\"\n",
    "    \n",
    "    continual_learning_task_vectors(dataset_name=dataset_name, n_experiences=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
