{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f8479448340>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/samuel_schapiro/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "/home/samuel_schapiro/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from avalanche.benchmarks import SplitMNIST, PermutedMNIST, RotatedMNIST\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.supervised import Naive\n",
    "from numpy.linalg import lstsq\n",
    "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics\n",
    "from avalanche.logging import InteractiveLogger,  TextLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "import numpy as np\n",
    "\n",
    "# Generate RotatedMNIST pseudo-tasks (e.g., 7 tasks with different rotations)\n",
    "rotated_benchmark = RotatedMNIST(n_experiences=7, seed=1234, rotations_list=[0, 15, 30, 45, 60, 75, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_schapiro/anaconda3/envs/py3.9.13/lib/python3.9/site-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 1 positional arguments to the Naive.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:06<00:00,  2.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8239\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7810\n",
      "-- >> End of training phase << --\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.7809666666666667,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task000': 0.8238722893238067}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Standard MNIST training\n",
    "split_mnist = SplitMNIST(n_experiences=1, seed=1234)\n",
    "model_base = SimpleMLP(num_classes=10).to(device)\n",
    "\n",
    "trainer = Naive(\n",
    "    model_base,\n",
    "    optimizer=torch.optim.SGD(model_base.parameters(), lr=0.01),\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    train_mb_size=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Pretrain on MNIST\n",
    "trainer.train(split_mnist.train_stream[0], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:35<00:00,  2.18it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4171\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8795\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:33<00:00,  2.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4825\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8587\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:42<00:00,  2.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5858\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8214\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:53<00:00,  2.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6689\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7912\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:50<00:00,  2.03it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7217\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7793\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:47<00:00,  2.06it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7567\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7687\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 469/469 [03:56<00:00,  1.99it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7786\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7615\n",
      "-- >> End of training phase << --\n"
     ]
    }
   ],
   "source": [
    "task_vectors = []  # To store pre-populated task vectors\n",
    "\n",
    "for experience in rotated_benchmark.train_stream:\n",
    "    model_tuned = SimpleMLP(num_classes=10).to(device)\n",
    "    model_tuned.load_state_dict(model_base.state_dict())  # Start from base model\n",
    "\n",
    "    # Fine-tune on rotated task\n",
    "    trainer = Naive(\n",
    "        model_tuned,\n",
    "        optimizer=torch.optim.SGD(model_tuned.parameters(), lr=0.01),\n",
    "        criterion=torch.nn.CrossEntropyLoss(),\n",
    "        train_mb_size=128,\n",
    "        device=device\n",
    "    )\n",
    "    trainer.train(experience, epochs=5)\n",
    "\n",
    "    # Compute task vector\n",
    "    task_vector = []\n",
    "    for p_base, p_tuned in zip(model_base.parameters(), model_tuned.parameters()):\n",
    "        task_vector.append((p_tuned.data - p_base.data).detach().cpu().numpy())\n",
    "    task_vector = np.concatenate([p.flatten() for p in task_vector])\n",
    "\n",
    "    # Store the task vector\n",
    "    task_vectors.append(task_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save pre-populated task vectors to a file\n",
    "with open(\"rotated_task_vectors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(task_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-populated task vectors\n",
    "with open(\"rotated_task_vectors.pkl\", \"rb\") as f:\n",
    "    task_vectors_active = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
