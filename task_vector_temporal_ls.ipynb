{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from avalanche.benchmarks import RotatedMNIST\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.supervised import Naive\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "\n",
    "# Import Localize and Stitch classes\n",
    "from localize_and_stitch import Localizer, Stitcher\n",
    "\n",
    "# Helper function to compute task vectors\n",
    "def compute_task_vector(pretrained_model, finetuned_model, device):\n",
    "    task_vector = []\n",
    "    for p_pre, p_fine in zip(pretrained_model.parameters(), finetuned_model.parameters()):\n",
    "        task_vector.append((p_fine.data - p_pre.data).detach().to(device))\n",
    "    return task_vector\n",
    "\n",
    "# Function to train on a single task and compute task vector\n",
    "def train_task(experience, model, pretrained_model, optimizer, criterion, device):\n",
    "    model.to(device)\n",
    "    pretrained_model.to(device)\n",
    "\n",
    "    # Fine-tune model on the task\n",
    "    trainer = Naive(\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_mb_size=128,\n",
    "        device=device\n",
    "    )\n",
    "    trainer.train(experience, epochs=5)\n",
    "\n",
    "    # Compute task vector\n",
    "    task_vector = compute_task_vector(pretrained_model, model, device)\n",
    "\n",
    "    # Reset pretrained_model to its original device\n",
    "    pretrained_model.to(\"cpu\")\n",
    "    return task_vector\n",
    "\n",
    "# Main function for continual learning\n",
    "def continual_learning_with_localize_and_stitch():\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Benchmark: RotatedMNIST for tasks with rotations\n",
    "    rotation_angles = [0, 15, 30, 45, 60, 75, 90, 115, 145, 175]\n",
    "    rotated_benchmark = RotatedMNIST(n_experiences=len(rotation_angles), seed=1234)\n",
    "\n",
    "    # Pretrain the base model\n",
    "    model_base = SimpleMLP(num_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model_base.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize the pretrained model\n",
    "    model_pretrained = SimpleMLP(num_classes=10).to(device)\n",
    "    model_pretrained.load_state_dict(model_base.state_dict())\n",
    "\n",
    "    # Active task vector set\n",
    "    task_vectors_active = []\n",
    "\n",
    "    # Localize and Stitch Arguments\n",
    "    graft_args = {\n",
    "        'sparsity': 0.01,  # 1% sparsity\n",
    "        'sigmoid_bias': 1.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'l1_strength': 0.0001,\n",
    "        'num_train_epochs': 5\n",
    "    }\n",
    "\n",
    "    # Loop over each experience in RotatedMNIST\n",
    "    for task_id, experience in enumerate(rotated_benchmark.train_stream):\n",
    "        print(f\"\\n### Training on Task {task_id+1} (Rotation: {rotation_angles[task_id]}Â°) ###\")\n",
    "\n",
    "        # Initialize the current model and load pretrained weights\n",
    "        model_current = SimpleMLP(num_classes=10).to(device)\n",
    "        model_current.load_state_dict(model_pretrained.state_dict())\n",
    "\n",
    "        # Train the model on the current task and compute task vector\n",
    "        task_vector = train_task(experience, model_current, model_pretrained, optimizer, criterion, device)\n",
    "\n",
    "        # Initialize Localizer for the current task\n",
    "        localizer = Localizer(\n",
    "            trainable_params=model_current.state_dict(),\n",
    "            model=model_current,\n",
    "            pretrained_model=model_pretrained,\n",
    "            finetuned_model=model_current,\n",
    "            dataset_name=\"RotatedMNIST\",\n",
    "            args=None,\n",
    "            graft_args=graft_args,\n",
    "            model_type=\"vit\"  # Example: Vision Transformer\n",
    "        )\n",
    "        \n",
    "        # Create binary masks and base patch\n",
    "        localizer.create_binary_masks()\n",
    "        base_patch = localizer.create_basepatch()\n",
    "\n",
    "        # Train graft to localize task-specific parameters\n",
    "        dataloader = experience.dataset\n",
    "        mask, proportion, val = localizer.train_graft(dataloader=dataloader, dataset_name=f\"RotatedMNIST-{rotation_angles[task_id]}\")\n",
    "\n",
    "        # Add the refined task vector to the active set\n",
    "        task_vectors_active.append(task_vector)\n",
    "\n",
    "        # Update the pretrained model\n",
    "        model_pretrained.load_state_dict(model_current.state_dict())\n",
    "\n",
    "    # Stitch the models together after all tasks\n",
    "    print(\"\\n### Stitching Models Together ###\")\n",
    "    stitcher = Stitcher(\n",
    "        trainable_params=model_pretrained.state_dict(),\n",
    "        model=model_pretrained,\n",
    "        pretrained_model=model_base,\n",
    "        finetuned_models=[model_pretrained for _ in task_vectors_active],  # One model per task\n",
    "        masks=[mask]  # Masks generated for each task\n",
    "    )\n",
    "    generalized_model = stitcher.interpolate_models()\n",
    "\n",
    "    # Evaluate the stitched model on all tasks\n",
    "    print(\"\\n### Evaluating Stitched Model ###\")\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(epoch=True, stream=True),\n",
    "        loggers=[InteractiveLogger()]\n",
    "    )\n",
    "    evaluator = Naive(generalized_model, optimizer, criterion, device=device, evaluator=eval_plugin)\n",
    "    evaluator.eval(rotated_benchmark.test_stream)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    continual_learning_with_localize_and_stitch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
